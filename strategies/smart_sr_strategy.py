"""Smart MTF S/R æ”¯æ’‘é˜»åŠ›ç­–ç•¥æ¨¡å—"""

import pandas as pd
import json
from typing import Dict, Any, Optional, Tuple
from indicators.smart_mtf_sr import compute_smart_mtf_sr
from config.config_loader import MonitorTarget

class SmartSRStrategy:
    """æ™ºèƒ½å¤šæ—¶é—´æ¡†æ¶æ”¯æ’‘é˜»åŠ›ç­–ç•¥
    
    è¯¥ç­–ç•¥ä¸æ˜¯ç‹¬ç«‹è¿è¡Œçš„ï¼Œè€Œæ˜¯ä½œä¸ºUTBotç­–ç•¥çš„è¾…åŠ©åˆ†æå·¥å…·ã€‚
    å½“UTBotè§¦å‘ä¹°å–ä¿¡å·æ—¶ï¼Œä¼šåŒæ—¶è®¡ç®—å½“å‰çš„æ”¯æ’‘é˜»åŠ›ä½æƒ…å†µï¼Œ
    å¹¶å°†åˆ†æç»“æœé™„åŠ åˆ°ä¿¡å·é€šçŸ¥ä¸­ã€‚
    """
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.name = "Smart_MTF_SR"
        
        # ä»é…ç½®ä¸­è¯»å–å‚æ•°ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é»˜è®¤å€¼
        self.timeframes = config.get("timeframes", ["15", "60", "240"])
        self.show_swings = config.get("show_swings", True)
        self.show_pivots = config.get("show_pivots", False)
        self.show_fibonacci = config.get("show_fibonacci", False)
        self.show_order_blocks = config.get("show_order_blocks", False)
        self.show_volume_profile = config.get("show_volume_profile", False)
        self.show_psychological_levels = config.get("show_psychological_levels", True)
        self.show_within_percent = config.get("show_within_percent", 2.5)
        self.lookback_swings = config.get("lookback_swings", 3)
        self.cluster_percent = config.get("cluster_percent", 0.25)
        self.top_n = config.get("top_n", 8)
        self.reaction_lookback = config.get("reaction_lookback", 100)
        self.sort_by = config.get("sort_by", "Confluence")
        self.alert_confluence = config.get("alert_confluence", 4)
        self.min_confluence = config.get("min_confluence", 2)
        
    def calculate_sr_analysis(self, df: pd.DataFrame, symbol: str, timeframe: str, exchange: str) -> Dict[str, Any]:
        """
        è®¡ç®—æ”¯æ’‘é˜»åŠ›ä½åˆ†æ
        
        Args:
            df: OHLCVæ•°æ®
            symbol: äº¤æ˜“å¯¹ç¬¦å·
            timeframe: æ—¶é—´æ¡†æ¶
            exchange: äº¤æ˜“æ‰€
            
        Returns:
            æ”¯æ’‘é˜»åŠ›ä½åˆ†æç»“æœ
        """
        try:
            # è®¡ç®—æ”¯æ’‘é˜»åŠ›ä½
            result_df = compute_smart_mtf_sr(
                df,
                symbol=symbol,
                timeframe=timeframe,
                exchange=exchange,
                timeframes=self.timeframes,
                show_swings=self.show_swings,
                show_pivots=self.show_pivots,
                show_fibonacci=self.show_fibonacci,
                show_order_blocks=self.show_order_blocks,
                show_volume_profile=self.show_volume_profile,
                show_psychological_levels=self.show_psychological_levels,
                show_within_percent=self.show_within_percent,
                lookback_swings=self.lookback_swings,
                cluster_percent=self.cluster_percent,
                top_n=self.top_n,
                reaction_lookback=self.reaction_lookback,
                sort_by=self.sort_by,
                alert_confluence=self.alert_confluence,
                min_confluence=self.min_confluence
            )
            
            # è·å–æœ€æ–°çš„æ”¯æ’‘é˜»åŠ›ä½æ•°æ®
            latest_sr_data = result_df.iloc[-1]['sr_data']
            
            if latest_sr_data and latest_sr_data != 'None':
                sr_json = json.loads(latest_sr_data)
                
                # æ ¼å¼åŒ–æ”¯æ’‘é˜»åŠ›ä½ä¿¡æ¯
                analysis = {
                    "timestamp": sr_json.get("timestamp"),
                    "current_price": sr_json.get("current_price"),
                    "total_zones": sr_json.get("total_zones", 0),
                    "support_count": sr_json.get("support_count", 0),
                    "resistance_count": sr_json.get("resistance_count", 0),
                    "max_confluence": sr_json.get("max_confluence", 0),
                    "max_reactions": sr_json.get("max_reactions", 0),
                    "key_support_levels": [],
                    "key_resistance_levels": [],
                    "market_context": ""
                }
                
                # æå–å…³é”®æ”¯æ’‘ä½ï¼ˆå‰3ä¸ªï¼‰
                support_levels = sr_json.get("support_levels", [])
                for level in support_levels[:3]:
                    analysis["key_support_levels"].append({
                        "price": level.get("level"),
                        "confluence": level.get("confluence"),
                        "reactions": level.get("reactions"),
                        "methods": ", ".join(level.get("methods", [])),
                        "distance_percent": abs(level.get("level", 0) - analysis["current_price"]) / analysis["current_price"] * 100
                    })
                
                # æå–å…³é”®é˜»åŠ›ä½ï¼ˆå‰3ä¸ªï¼‰
                resistance_levels = sr_json.get("resistance_levels", [])
                for level in resistance_levels[:3]:
                    analysis["key_resistance_levels"].append({
                        "price": level.get("level"),
                        "confluence": level.get("confluence"),
                        "reactions": level.get("reactions"),
                        "methods": ", ".join(level.get("methods", [])),
                        "distance_percent": abs(level.get("level", 0) - analysis["current_price"]) / analysis["current_price"] * 100
                    })
                
                # ç”Ÿæˆå¸‚åœºä¸Šä¸‹æ–‡åˆ†æ
                analysis["market_context"] = self._generate_market_context(analysis)
                
                return analysis
            else:
                return {
                    "error": "æ— æ³•è·å–æ”¯æ’‘é˜»åŠ›ä½æ•°æ®",
                    "current_price": float(df['close'].iloc[-1]),
                    "total_zones": 0
                }
                
        except Exception as e:
            return {
                "error": f"è®¡ç®—æ”¯æ’‘é˜»åŠ›ä½æ—¶å‡ºé”™: {str(e)}",
                "current_price": float(df['close'].iloc[-1]) if not df.empty else 0,
                "total_zones": 0
            }
    
    def _generate_market_context(self, analysis: Dict[str, Any]) -> str:
        """ç”Ÿæˆå¸‚åœºä¸Šä¸‹æ–‡åˆ†æ"""
        context_parts = []
        
        # æ•´ä½“å¼ºåº¦åˆ†æ
        if analysis["max_confluence"] >= 4:
            context_parts.append("ğŸ”¥ å‘ç°é«˜æ±‡èšåº¦æ”¯æ’‘é˜»åŠ›åŒºåŸŸ")
        elif analysis["max_confluence"] >= 2:
            context_parts.append("âš¡ å­˜åœ¨ä¸­ç­‰å¼ºåº¦æ”¯æ’‘é˜»åŠ›åŒºåŸŸ")
        else:
            context_parts.append("ğŸ“Š æ”¯æ’‘é˜»åŠ›åŒºåŸŸè¾ƒå¼±")
        
        # æœ€è¿‘çš„å…³é”®ä½åˆ†æ
        nearest_support = None
        nearest_resistance = None
        
        for support in analysis["key_support_levels"]:
            if support["distance_percent"] <= 2.0:  # 2%ä»¥å†…
                nearest_support = support
                break
        
        for resistance in analysis["key_resistance_levels"]:
            if resistance["distance_percent"] <= 2.0:  # 2%ä»¥å†…
                nearest_resistance = resistance
                break
        
        if nearest_support:
            context_parts.append(f"ğŸ›¡ï¸ æ¥è¿‘å…³é”®æ”¯æ’‘ä½ {nearest_support['price']:.2f} (æ±‡èšåº¦:{nearest_support['confluence']})")
        
        if nearest_resistance:
            context_parts.append(f"ğŸš§ æ¥è¿‘å…³é”®é˜»åŠ›ä½ {nearest_resistance['price']:.2f} (æ±‡èšåº¦:{nearest_resistance['confluence']})")
        
        # åŒºåŸŸå¹³è¡¡åˆ†æ
        if analysis["support_count"] > analysis["resistance_count"] * 1.5:
            context_parts.append("ğŸ“ˆ ä¸‹æ–¹æ”¯æ’‘è¾ƒå¼º")
        elif analysis["resistance_count"] > analysis["support_count"] * 1.5:
            context_parts.append("ğŸ“‰ ä¸Šæ–¹é˜»åŠ›è¾ƒå¼º")
        else:
            context_parts.append("âš–ï¸ æ”¯æ’‘é˜»åŠ›ç›¸å¯¹å¹³è¡¡")
        
        return " | ".join(context_parts)
    
    def enhance_utbot_signal(self, signal_data: Dict[str, Any], df: pd.DataFrame) -> Dict[str, Any]:
        """
        ä¸ºUTBotä¿¡å·å¢å¼ºæ”¯æ’‘é˜»åŠ›ä½åˆ†æ
        
        Args:
            signal_data: UTBotçš„ä¿¡å·æ•°æ®
            df: OHLCVæ•°æ®
            
        Returns:
            å¢å¼ºåçš„ä¿¡å·æ•°æ®
        """
        try:
            # ä»signal_dataä¸­æå–å¿…è¦ä¿¡æ¯
            symbol = signal_data.get("symbol", "ETH")
            timeframe = signal_data.get("timeframe", "5m")
            exchange = signal_data.get("exchange", "okx")
            
            # è®¡ç®—æ”¯æ’‘é˜»åŠ›ä½åˆ†æ
            sr_analysis = self.calculate_sr_analysis(df, symbol, timeframe, exchange)
            
            # å°†æ”¯æ’‘é˜»åŠ›ä½åˆ†ææ·»åŠ åˆ°ä¿¡å·æ•°æ®ä¸­
            enhanced_signal = signal_data.copy()
            enhanced_signal["sr_analysis"] = sr_analysis
            
            # ç”Ÿæˆå¢å¼ºçš„æ¶ˆæ¯æ–‡æœ¬
            enhanced_signal["enhanced_message"] = self._format_enhanced_message(signal_data, sr_analysis)
            
            return enhanced_signal
            
        except Exception as e:
            # å¦‚æœåˆ†æå¤±è´¥ï¼Œè¿”å›åŸå§‹ä¿¡å·æ•°æ®å¹¶æ·»åŠ é”™è¯¯ä¿¡æ¯
            enhanced_signal = signal_data.copy()
            enhanced_signal["sr_analysis"] = {"error": f"S/Råˆ†æå¤±è´¥: {str(e)}"}
            enhanced_signal["enhanced_message"] = signal_data.get("message", "")
            return enhanced_signal
    
    def _format_enhanced_message(self, signal_data: Dict[str, Any], sr_analysis: Dict[str, Any]) -> str:
        """æ ¼å¼åŒ–å¢å¼ºæ¶ˆæ¯ - åªåŒ…å«S/Råˆ†æä¿¡æ¯"""
        try:
            # åªåŒ…å«æ”¯æ’‘é˜»åŠ›ä½åˆ†æï¼Œä¸é‡å¤ä¿¡å·ä¿¡æ¯
            message_parts = []
            
            # æ·»åŠ æ”¯æ’‘é˜»åŠ›ä½åˆ†æ
            if "error" not in sr_analysis:
                message_parts.append(f"ğŸ“Š æ”¯æ’‘é˜»åŠ›ä½åˆ†æ:")
                message_parts.append(f"ğŸ¯ å‘ç° {sr_analysis.get('total_zones', 0)} ä¸ªS/RåŒºåŸŸ")
                message_parts.append(f"ğŸ“ˆ æ”¯æ’‘ä½: {sr_analysis.get('support_count', 0)} ä¸ª")
                message_parts.append(f"ğŸ“‰ é˜»åŠ›ä½: {sr_analysis.get('resistance_count', 0)} ä¸ª")
                message_parts.append(f"âš¡ æœ€å¤§æ±‡èšåº¦: {sr_analysis.get('max_confluence', 0)}")
                
                # å¸‚åœºä¸Šä¸‹æ–‡
                if sr_analysis.get("market_context"):
                    message_parts.append(f"\nğŸ” å¸‚åœºæƒ…å†µ: {sr_analysis['market_context']}")
                
                # å…³é”®ä½ç½®ä¿¡æ¯
                key_supports = sr_analysis.get("key_support_levels", [])
                if key_supports:
                    message_parts.append(f"\nğŸ›¡ï¸ å…³é”®æ”¯æ’‘ä½:")
                    for i, support in enumerate(key_supports[:2], 1):
                        message_parts.append(f"  {i}. ${support['price']:.2f} (æ±‡èšåº¦:{support['confluence']}, è·ç¦»:{support['distance_percent']:.1f}%)")
                
                key_resistances = sr_analysis.get("key_resistance_levels", [])
                if key_resistances:
                    message_parts.append(f"\nğŸš§ å…³é”®é˜»åŠ›ä½:")
                    for i, resistance in enumerate(key_resistances[:2], 1):
                        message_parts.append(f"  {i}. ${resistance['price']:.2f} (æ±‡èšåº¦:{resistance['confluence']}, è·ç¦»:{resistance['distance_percent']:.1f}%)")
            else:
                message_parts.append(f"âš ï¸ S/Råˆ†æ: {sr_analysis.get('error', 'æœªçŸ¥é”™è¯¯')}")
            
            return "\n".join(message_parts)
            
        except Exception as e:
            # å¦‚æœæ ¼å¼åŒ–å¤±è´¥ï¼Œè¿”å›é”™è¯¯ä¿¡æ¯
            return f"âš ï¸ S/Råˆ†ææ ¼å¼åŒ–å¤±è´¥: {str(e)}"
    
    def get_strategy_info(self) -> Dict[str, Any]:
        """è·å–ç­–ç•¥ä¿¡æ¯"""
        return {
            "name": self.name,
            "description": "æ™ºèƒ½å¤šæ—¶é—´æ¡†æ¶æ”¯æ’‘é˜»åŠ›ä½åˆ†æç­–ç•¥ï¼ˆUTBotè¾…åŠ©ï¼‰",
            "version": "1.0",
            "type": "auxiliary",  # è¾…åŠ©ç­–ç•¥
            "trigger_mode": "on_utbot_signal",  # åœ¨UTBotä¿¡å·è§¦å‘æ—¶è®¡ç®—
            "config": self.config,
            "parameters": {
                "timeframes": self.timeframes,
                "show_swings": self.show_swings,
                "show_pivots": self.show_pivots,
                "show_fibonacci": self.show_fibonacci,
                "show_order_blocks": self.show_order_blocks,
                "show_volume_profile": self.show_volume_profile,
                "show_psychological_levels": self.show_psychological_levels,
                "cluster_percent": self.cluster_percent,
                "min_confluence": self.min_confluence
            }
        }
